{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 4\n",
    "\n",
    "In this notebook we rank systems using metrics on GLUE benchmark, their efficiency rate and data about social bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading region bounding boxes for computing carbon emissions region, this may take a moment...\n",
      " 454/454... rate=436.31 Hz, eta=0:00:00, total=0:00:010\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data_sapiens/.local/lib/python3.8/site-packages/experiment_impact_tracker/data_interface.py:37: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from votenrank import Leaderboard\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We multiply all efficiency values by -1 because they have to be minimized and not maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wnli.eval_accuracy</th>\n",
       "      <th>cola.eval_matthews_correlation</th>\n",
       "      <th>stsb.eval_pearson</th>\n",
       "      <th>stsb.eval_spearmanr</th>\n",
       "      <th>rte.eval_accuracy</th>\n",
       "      <th>mrpc.eval_accuracy</th>\n",
       "      <th>mrpc.eval_f1</th>\n",
       "      <th>sst2.eval_accuracy</th>\n",
       "      <th>qnli.eval_accuracy</th>\n",
       "      <th>qqp.eval_accuracy</th>\n",
       "      <th>qqp.eval_f1</th>\n",
       "      <th>mnli.eval_accuracy</th>\n",
       "      <th>mnli-mm.eval_accuracy</th>\n",
       "      <th>anti_crows_score</th>\n",
       "      <th>stereoset_intra_icat</th>\n",
       "      <th>stereoset_inter_icat</th>\n",
       "      <th>winogender_acc_difference</th>\n",
       "      <th>winobias_acc_difference</th>\n",
       "      <th>rte_gpu_hours</th>\n",
       "      <th>stsb_kg_carbon</th>\n",
       "      <th>wnli_total_power</th>\n",
       "      <th>stsb_total_power</th>\n",
       "      <th>mnli_total_power</th>\n",
       "      <th>qnli_kg_carbon</th>\n",
       "      <th>mnli-mm_exp_len_hours</th>\n",
       "      <th>qnli_exp_len_hours</th>\n",
       "      <th>qqp_exp_len_hours</th>\n",
       "      <th>rte_total_power</th>\n",
       "      <th>rte_kg_carbon</th>\n",
       "      <th>sst2_kg_carbon</th>\n",
       "      <th>qqp_kg_carbon</th>\n",
       "      <th>rte_exp_len_hours</th>\n",
       "      <th>qnli_gpu_hours</th>\n",
       "      <th>qqp_gpu_hours</th>\n",
       "      <th>mnli_exp_len_hours</th>\n",
       "      <th>mrpc_gpu_hours</th>\n",
       "      <th>wnli_gpu_hours</th>\n",
       "      <th>wnli_kg_carbon</th>\n",
       "      <th>stsb_exp_len_hours</th>\n",
       "      <th>mrpc_kg_carbon</th>\n",
       "      <th>mnli-mm_gpu_hours</th>\n",
       "      <th>mnli_kg_carbon</th>\n",
       "      <th>wnli_exp_len_hours</th>\n",
       "      <th>stsb_gpu_hours</th>\n",
       "      <th>sst2_gpu_hours</th>\n",
       "      <th>mnli_gpu_hours</th>\n",
       "      <th>qqp_total_power</th>\n",
       "      <th>cola_kg_carbon</th>\n",
       "      <th>cola_gpu_hours</th>\n",
       "      <th>cola_total_power</th>\n",
       "      <th>mrpc_total_power</th>\n",
       "      <th>sst2_total_power</th>\n",
       "      <th>sst2_exp_len_hours</th>\n",
       "      <th>mrpc_exp_len_hours</th>\n",
       "      <th>cola_exp_len_hours</th>\n",
       "      <th>mnli-mm_total_power</th>\n",
       "      <th>mnli-mm_kg_carbon</th>\n",
       "      <th>qnli_total_power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distilbert-base-uncased</th>\n",
       "      <td>54.6</td>\n",
       "      <td>53.9</td>\n",
       "      <td>87.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>62.9</td>\n",
       "      <td>84.7</td>\n",
       "      <td>89.6</td>\n",
       "      <td>90.9</td>\n",
       "      <td>89.2</td>\n",
       "      <td>90.4</td>\n",
       "      <td>87.1</td>\n",
       "      <td>82.2</td>\n",
       "      <td>82.3</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>-0.009423</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-1.069909</td>\n",
       "      <td>-0.062459</td>\n",
       "      <td>-4.480067</td>\n",
       "      <td>-0.616156</td>\n",
       "      <td>-2.227646</td>\n",
       "      <td>-0.004557</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.010247</td>\n",
       "      <td>-0.161034</td>\n",
       "      <td>-0.012203</td>\n",
       "      <td>-0.452701</td>\n",
       "      <td>-1.095744</td>\n",
       "      <td>-4.265462</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.016014</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-1.441347</td>\n",
       "      <td>-0.268262</td>\n",
       "      <td>-0.003287</td>\n",
       "      <td>-0.010926</td>\n",
       "      <td>-0.096281</td>\n",
       "      <td>-1.447840</td>\n",
       "      <td>-0.642252</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>-0.005013</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.040868</td>\n",
       "      <td>-0.150034</td>\n",
       "      <td>-0.009880</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>-1.059574</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.249105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>42.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>89.7</td>\n",
       "      <td>89.3</td>\n",
       "      <td>69.7</td>\n",
       "      <td>85.8</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>91.5</td>\n",
       "      <td>91.2</td>\n",
       "      <td>88.2</td>\n",
       "      <td>84.4</td>\n",
       "      <td>84.9</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.7279</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>-0.017499</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-0.009909</td>\n",
       "      <td>-2.095817</td>\n",
       "      <td>-0.126461</td>\n",
       "      <td>-8.408221</td>\n",
       "      <td>-1.312409</td>\n",
       "      <td>-4.697835</td>\n",
       "      <td>-0.008031</td>\n",
       "      <td>-0.002014</td>\n",
       "      <td>-0.018614</td>\n",
       "      <td>-0.329854</td>\n",
       "      <td>-0.022321</td>\n",
       "      <td>-0.861943</td>\n",
       "      <td>-2.067670</td>\n",
       "      <td>-8.857196</td>\n",
       "      <td>-0.012200</td>\n",
       "      <td>-0.001466</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.028338</td>\n",
       "      <td>-0.001327</td>\n",
       "      <td>-2.742530</td>\n",
       "      <td>-0.525491</td>\n",
       "      <td>-0.004337</td>\n",
       "      <td>-0.020176</td>\n",
       "      <td>-0.178940</td>\n",
       "      <td>-2.741965</td>\n",
       "      <td>-1.315557</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>-0.020750</td>\n",
       "      <td>-0.008787</td>\n",
       "      <td>-0.005294</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>-0.283502</td>\n",
       "      <td>-0.018210</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>-1.959109</td>\n",
       "      <td>-0.491214</td>\n",
       "      <td>-0.504366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-base</th>\n",
       "      <td>56.3</td>\n",
       "      <td>60.4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>90.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>89.1</td>\n",
       "      <td>92.1</td>\n",
       "      <td>94.1</td>\n",
       "      <td>92.5</td>\n",
       "      <td>91.5</td>\n",
       "      <td>88.7</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>-0.016651</td>\n",
       "      <td>-0.002488</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.009921</td>\n",
       "      <td>-2.157483</td>\n",
       "      <td>-0.130972</td>\n",
       "      <td>-8.096763</td>\n",
       "      <td>-1.342347</td>\n",
       "      <td>-5.054267</td>\n",
       "      <td>-0.008468</td>\n",
       "      <td>-0.002123</td>\n",
       "      <td>-0.019406</td>\n",
       "      <td>-0.330371</td>\n",
       "      <td>-0.020526</td>\n",
       "      <td>-0.898159</td>\n",
       "      <td>-2.097117</td>\n",
       "      <td>-10.052896</td>\n",
       "      <td>-0.011822</td>\n",
       "      <td>-0.001870</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>-0.029009</td>\n",
       "      <td>-0.001486</td>\n",
       "      <td>-2.684118</td>\n",
       "      <td>-0.540953</td>\n",
       "      <td>-0.004431</td>\n",
       "      <td>-0.020887</td>\n",
       "      <td>-0.184717</td>\n",
       "      <td>-2.694672</td>\n",
       "      <td>-1.317620</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>-0.021341</td>\n",
       "      <td>-0.009321</td>\n",
       "      <td>-0.005925</td>\n",
       "      <td>-0.077397</td>\n",
       "      <td>-0.287918</td>\n",
       "      <td>-0.017837</td>\n",
       "      <td>-0.036028</td>\n",
       "      <td>-1.985482</td>\n",
       "      <td>-0.497827</td>\n",
       "      <td>-0.522354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilroberta-base</th>\n",
       "      <td>51.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>86.9</td>\n",
       "      <td>86.7</td>\n",
       "      <td>64.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>88.7</td>\n",
       "      <td>91.8</td>\n",
       "      <td>90.9</td>\n",
       "      <td>90.9</td>\n",
       "      <td>87.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.3</td>\n",
       "      <td>0.3687</td>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>-0.732750</td>\n",
       "      <td>-0.061111</td>\n",
       "      <td>-1.757867</td>\n",
       "      <td>-0.558800</td>\n",
       "      <td>-1.494409</td>\n",
       "      <td>-0.004944</td>\n",
       "      <td>-0.001240</td>\n",
       "      <td>-0.010311</td>\n",
       "      <td>-0.136711</td>\n",
       "      <td>-0.012071</td>\n",
       "      <td>-0.470668</td>\n",
       "      <td>-1.116539</td>\n",
       "      <td>-1.956517</td>\n",
       "      <td>-0.006609</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.016254</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-1.424475</td>\n",
       "      <td>-0.183725</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>-0.011469</td>\n",
       "      <td>-0.101979</td>\n",
       "      <td>-1.427339</td>\n",
       "      <td>-0.545243</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.012039</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>-0.002901</td>\n",
       "      <td>-0.041124</td>\n",
       "      <td>-0.159032</td>\n",
       "      <td>-0.010284</td>\n",
       "      <td>-0.020594</td>\n",
       "      <td>-0.718782</td>\n",
       "      <td>-0.180223</td>\n",
       "      <td>-0.243730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albert-base-v2</th>\n",
       "      <td>54.1</td>\n",
       "      <td>57.1</td>\n",
       "      <td>90.8</td>\n",
       "      <td>90.4</td>\n",
       "      <td>77.5</td>\n",
       "      <td>87.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91.8</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.6</td>\n",
       "      <td>87.4</td>\n",
       "      <td>84.4</td>\n",
       "      <td>84.6</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.7770</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>-0.017268</td>\n",
       "      <td>-0.002204</td>\n",
       "      <td>-0.001224</td>\n",
       "      <td>-0.008790</td>\n",
       "      <td>-2.660270</td>\n",
       "      <td>-0.132740</td>\n",
       "      <td>-9.933616</td>\n",
       "      <td>-1.447277</td>\n",
       "      <td>-7.815161</td>\n",
       "      <td>-0.008678</td>\n",
       "      <td>-0.002176</td>\n",
       "      <td>-0.016236</td>\n",
       "      <td>-0.436818</td>\n",
       "      <td>-0.020173</td>\n",
       "      <td>-0.911492</td>\n",
       "      <td>-2.140980</td>\n",
       "      <td>-12.785114</td>\n",
       "      <td>-0.013097</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>-0.022631</td>\n",
       "      <td>-0.001735</td>\n",
       "      <td>-2.924104</td>\n",
       "      <td>-0.667019</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>-0.018657</td>\n",
       "      <td>-0.147321</td>\n",
       "      <td>-2.923310</td>\n",
       "      <td>-1.742160</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>-0.014013</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>-0.006921</td>\n",
       "      <td>-0.064754</td>\n",
       "      <td>-0.195145</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-2.292798</td>\n",
       "      <td>-0.574881</td>\n",
       "      <td>-0.529408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deberta-base</th>\n",
       "      <td>56.3</td>\n",
       "      <td>62.9</td>\n",
       "      <td>91.1</td>\n",
       "      <td>90.8</td>\n",
       "      <td>72.6</td>\n",
       "      <td>89.8</td>\n",
       "      <td>92.7</td>\n",
       "      <td>94.5</td>\n",
       "      <td>92.8</td>\n",
       "      <td>91.6</td>\n",
       "      <td>88.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0.5159</td>\n",
       "      <td>0.4248</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.003464</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>-0.013816</td>\n",
       "      <td>-2.923224</td>\n",
       "      <td>-0.238413</td>\n",
       "      <td>-17.840316</td>\n",
       "      <td>-2.713213</td>\n",
       "      <td>-7.512733</td>\n",
       "      <td>-0.017037</td>\n",
       "      <td>-0.004272</td>\n",
       "      <td>-0.027810</td>\n",
       "      <td>-0.524498</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>-1.681553</td>\n",
       "      <td>-3.381128</td>\n",
       "      <td>-10.030674</td>\n",
       "      <td>-0.017665</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>-0.000493</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>-4.618241</td>\n",
       "      <td>-0.732950</td>\n",
       "      <td>-0.006313</td>\n",
       "      <td>-0.028744</td>\n",
       "      <td>-0.254984</td>\n",
       "      <td>-4.553410</td>\n",
       "      <td>-2.091857</td>\n",
       "      <td>-0.003347</td>\n",
       "      <td>-0.030298</td>\n",
       "      <td>-0.013349</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>-0.446843</td>\n",
       "      <td>-0.027093</td>\n",
       "      <td>-0.058610</td>\n",
       "      <td>-3.716869</td>\n",
       "      <td>-0.931943</td>\n",
       "      <td>-0.950864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>47.6</td>\n",
       "      <td>41.3</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>79.7</td>\n",
       "      <td>86.3</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>82.4</td>\n",
       "      <td>83.1</td>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9255</td>\n",
       "      <td>-0.018881</td>\n",
       "      <td>-0.002791</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-2.095429</td>\n",
       "      <td>-0.157637</td>\n",
       "      <td>-6.617313</td>\n",
       "      <td>-1.624914</td>\n",
       "      <td>-4.218253</td>\n",
       "      <td>-0.011766</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>-0.018546</td>\n",
       "      <td>-0.352342</td>\n",
       "      <td>-0.023214</td>\n",
       "      <td>-1.106762</td>\n",
       "      <td>-2.460369</td>\n",
       "      <td>-7.331448</td>\n",
       "      <td>-0.012802</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.028604</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-3.218423</td>\n",
       "      <td>-0.525394</td>\n",
       "      <td>-0.004131</td>\n",
       "      <td>-0.022286</td>\n",
       "      <td>-0.179276</td>\n",
       "      <td>-3.213799</td>\n",
       "      <td>-1.405244</td>\n",
       "      <td>-0.002057</td>\n",
       "      <td>-0.020568</td>\n",
       "      <td>-0.008203</td>\n",
       "      <td>-0.006397</td>\n",
       "      <td>-0.073969</td>\n",
       "      <td>-0.245803</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>-0.031311</td>\n",
       "      <td>-1.997422</td>\n",
       "      <td>-0.500820</td>\n",
       "      <td>-0.628704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wnli.eval_accuracy  cola.eval_matthews_correlation  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased                54.6                            53.9   \n",
       "bert-base-uncased                      42.5                            59.0   \n",
       "roberta-base                           56.3                            60.4   \n",
       "distilroberta-base                     51.5                            56.1   \n",
       "albert-base-v2                         54.1                            57.1   \n",
       "deberta-base                           56.3                            62.9   \n",
       "gpt2                                   47.6                            41.3   \n",
       "\n",
       "                         stsb.eval_pearson  stsb.eval_spearmanr  \\\n",
       "model_name                                                        \n",
       "distilbert-base-uncased               87.1                 86.8   \n",
       "bert-base-uncased                     89.7                 89.3   \n",
       "roberta-base                          90.6                 90.4   \n",
       "distilroberta-base                    86.9                 86.7   \n",
       "albert-base-v2                        90.8                 90.4   \n",
       "deberta-base                          91.1                 90.8   \n",
       "gpt2                                  86.0                 86.0   \n",
       "\n",
       "                         rte.eval_accuracy  mrpc.eval_accuracy  mrpc.eval_f1  \\\n",
       "model_name                                                                     \n",
       "distilbert-base-uncased               62.9                84.7          89.6   \n",
       "bert-base-uncased                     69.7                85.8          90.0   \n",
       "roberta-base                          76.0                89.1          92.1   \n",
       "distilroberta-base                    64.5                84.0          88.7   \n",
       "albert-base-v2                        77.5                87.6          91.0   \n",
       "deberta-base                          72.6                89.8          92.7   \n",
       "gpt2                                  66.7                79.7          86.3   \n",
       "\n",
       "                         sst2.eval_accuracy  qnli.eval_accuracy  \\\n",
       "model_name                                                        \n",
       "distilbert-base-uncased                90.9                89.2   \n",
       "bert-base-uncased                      92.9                91.5   \n",
       "roberta-base                           94.1                92.5   \n",
       "distilroberta-base                     91.8                90.9   \n",
       "albert-base-v2                         91.8                91.0   \n",
       "deberta-base                           94.5                92.8   \n",
       "gpt2                                   92.0                89.0   \n",
       "\n",
       "                         qqp.eval_accuracy  qqp.eval_f1  mnli.eval_accuracy  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased               90.4         87.1                82.2   \n",
       "bert-base-uncased                     91.2         88.2                84.4   \n",
       "roberta-base                          91.5         88.7                87.5   \n",
       "distilroberta-base                    90.9         87.8                84.0   \n",
       "albert-base-v2                        90.6         87.4                84.4   \n",
       "deberta-base                          91.6         88.7                87.9   \n",
       "gpt2                                  90.1         86.8                82.4   \n",
       "\n",
       "                         mnli-mm.eval_accuracy  anti_crows_score  \\\n",
       "model_name                                                         \n",
       "distilbert-base-uncased                   82.3            0.4098   \n",
       "bert-base-uncased                         84.9            0.4138   \n",
       "roberta-base                              87.2            0.3773   \n",
       "distilroberta-base                        84.3            0.3687   \n",
       "albert-base-v2                            84.6            0.4410   \n",
       "deberta-base                              87.9            0.5159   \n",
       "gpt2                                      83.1            0.4317   \n",
       "\n",
       "                         stereoset_intra_icat  stereoset_inter_icat  \\\n",
       "model_name                                                            \n",
       "distilbert-base-uncased                0.6998                0.7528   \n",
       "bert-base-uncased                      0.7279                0.6700   \n",
       "roberta-base                           0.6750                0.3995   \n",
       "distilroberta-base                     0.6833                0.6247   \n",
       "albert-base-v2                         0.6901                0.7770   \n",
       "deberta-base                           0.4248                0.4035   \n",
       "gpt2                                   0.6975                0.6490   \n",
       "\n",
       "                         winogender_acc_difference  winobias_acc_difference  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased                     0.9917                   0.9981   \n",
       "bert-base-uncased                           0.9875                   0.9552   \n",
       "roberta-base                                0.9708                   0.9609   \n",
       "distilroberta-base                          0.9958                   0.9861   \n",
       "albert-base-v2                              0.9958                   0.9924   \n",
       "deberta-base                                0.9917                   0.9867   \n",
       "gpt2                                        0.9958                   0.9255   \n",
       "\n",
       "                         rte_gpu_hours  stsb_kg_carbon  wnli_total_power  \\\n",
       "model_name                                                                 \n",
       "distilbert-base-uncased      -0.009423       -0.001357         -0.001057   \n",
       "bert-base-uncased            -0.017499       -0.002484         -0.001444   \n",
       "roberta-base                 -0.016651       -0.002488         -0.001763   \n",
       "distilroberta-base           -0.008836       -0.001292         -0.000875   \n",
       "albert-base-v2               -0.017268       -0.002204         -0.001224   \n",
       "deberta-base                 -0.030452       -0.003464         -0.001967   \n",
       "gpt2                         -0.018881       -0.002791         -0.001605   \n",
       "\n",
       "                         stsb_total_power  mnli_total_power  qnli_kg_carbon  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased         -0.005413         -1.069909       -0.062459   \n",
       "bert-base-uncased               -0.009909         -2.095817       -0.126461   \n",
       "roberta-base                    -0.009921         -2.157483       -0.130972   \n",
       "distilroberta-base              -0.005154         -0.732750       -0.061111   \n",
       "albert-base-v2                  -0.008790         -2.660270       -0.132740   \n",
       "deberta-base                    -0.013816         -2.923224       -0.238413   \n",
       "gpt2                            -0.011132         -2.095429       -0.157637   \n",
       "\n",
       "                         mnli-mm_exp_len_hours  qnli_exp_len_hours  \\\n",
       "model_name                                                           \n",
       "distilbert-base-uncased              -4.480067           -0.616156   \n",
       "bert-base-uncased                    -8.408221           -1.312409   \n",
       "roberta-base                         -8.096763           -1.342347   \n",
       "distilroberta-base                   -1.757867           -0.558800   \n",
       "albert-base-v2                       -9.933616           -1.447277   \n",
       "deberta-base                        -17.840316           -2.713213   \n",
       "gpt2                                 -6.617313           -1.624914   \n",
       "\n",
       "                         qqp_exp_len_hours  rte_total_power  rte_kg_carbon  \\\n",
       "model_name                                                                   \n",
       "distilbert-base-uncased          -2.227646        -0.004557      -0.001143   \n",
       "bert-base-uncased                -4.697835        -0.008031      -0.002014   \n",
       "roberta-base                     -5.054267        -0.008468      -0.002123   \n",
       "distilroberta-base               -1.494409        -0.004944      -0.001240   \n",
       "albert-base-v2                   -7.815161        -0.008678      -0.002176   \n",
       "deberta-base                     -7.512733        -0.017037      -0.004272   \n",
       "gpt2                             -4.218253        -0.011766      -0.002950   \n",
       "\n",
       "                         sst2_kg_carbon  qqp_kg_carbon  rte_exp_len_hours  \\\n",
       "model_name                                                                  \n",
       "distilbert-base-uncased       -0.010247      -0.161034          -0.012203   \n",
       "bert-base-uncased             -0.018614      -0.329854          -0.022321   \n",
       "roberta-base                  -0.019406      -0.330371          -0.020526   \n",
       "distilroberta-base            -0.010311      -0.136711          -0.012071   \n",
       "albert-base-v2                -0.016236      -0.436818          -0.020173   \n",
       "deberta-base                  -0.027810      -0.524498          -0.035368   \n",
       "gpt2                          -0.018546      -0.352342          -0.023214   \n",
       "\n",
       "                         qnli_gpu_hours  qqp_gpu_hours  mnli_exp_len_hours  \\\n",
       "model_name                                                                   \n",
       "distilbert-base-uncased       -0.452701      -1.095744           -4.265462   \n",
       "bert-base-uncased             -0.861943      -2.067670           -8.857196   \n",
       "roberta-base                  -0.898159      -2.097117          -10.052896   \n",
       "distilroberta-base            -0.470668      -1.116539           -1.956517   \n",
       "albert-base-v2                -0.911492      -2.140980          -12.785114   \n",
       "deberta-base                  -1.681553      -3.381128          -10.030674   \n",
       "gpt2                          -1.106762      -2.460369           -7.331448   \n",
       "\n",
       "                         mrpc_gpu_hours  wnli_gpu_hours  wnli_kg_carbon  \\\n",
       "model_name                                                                \n",
       "distilbert-base-uncased       -0.006452       -0.000999       -0.000265   \n",
       "bert-base-uncased             -0.012200       -0.001466       -0.000362   \n",
       "roberta-base                  -0.011822       -0.001870       -0.000442   \n",
       "distilroberta-base            -0.006609       -0.001007       -0.000219   \n",
       "albert-base-v2                -0.013097       -0.001538       -0.000307   \n",
       "deberta-base                  -0.017665       -0.003556       -0.000493   \n",
       "gpt2                          -0.012802       -0.002107       -0.000402   \n",
       "\n",
       "                         stsb_exp_len_hours  mrpc_kg_carbon  \\\n",
       "model_name                                                    \n",
       "distilbert-base-uncased           -0.016014       -0.000791   \n",
       "bert-base-uncased                 -0.028338       -0.001327   \n",
       "roberta-base                      -0.029009       -0.001486   \n",
       "distilroberta-base                -0.016254       -0.000727   \n",
       "albert-base-v2                    -0.022631       -0.001735   \n",
       "deberta-base                      -0.043224       -0.001888   \n",
       "gpt2                              -0.028604       -0.001604   \n",
       "\n",
       "                         mnli-mm_gpu_hours  mnli_kg_carbon  \\\n",
       "model_name                                                   \n",
       "distilbert-base-uncased          -1.441347       -0.268262   \n",
       "bert-base-uncased                -2.742530       -0.525491   \n",
       "roberta-base                     -2.684118       -0.540953   \n",
       "distilroberta-base               -1.424475       -0.183725   \n",
       "albert-base-v2                   -2.924104       -0.667019   \n",
       "deberta-base                     -4.618241       -0.732950   \n",
       "gpt2                             -3.218423       -0.525394   \n",
       "\n",
       "                         wnli_exp_len_hours  stsb_gpu_hours  sst2_gpu_hours  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased           -0.003287       -0.010926       -0.096281   \n",
       "bert-base-uncased                 -0.004337       -0.020176       -0.178940   \n",
       "roberta-base                      -0.004431       -0.020887       -0.184717   \n",
       "distilroberta-base                -0.002817       -0.011469       -0.101979   \n",
       "albert-base-v2                    -0.002903       -0.018657       -0.147321   \n",
       "deberta-base                      -0.006313       -0.028744       -0.254984   \n",
       "gpt2                              -0.004131       -0.022286       -0.179276   \n",
       "\n",
       "                         mnli_gpu_hours  qqp_total_power  cola_kg_carbon  \\\n",
       "model_name                                                                 \n",
       "distilbert-base-uncased       -1.447840        -0.642252       -0.001257   \n",
       "bert-base-uncased             -2.741965        -1.315557       -0.002203   \n",
       "roberta-base                  -2.694672        -1.317620       -0.002337   \n",
       "distilroberta-base            -1.427339        -0.545243       -0.001277   \n",
       "albert-base-v2                -2.923310        -1.742160       -0.001577   \n",
       "deberta-base                  -4.553410        -2.091857       -0.003347   \n",
       "gpt2                          -3.213799        -1.405244       -0.002057   \n",
       "\n",
       "                         cola_gpu_hours  cola_total_power  mrpc_total_power  \\\n",
       "model_name                                                                    \n",
       "distilbert-base-uncased       -0.011305         -0.005013         -0.003155   \n",
       "bert-base-uncased             -0.020750         -0.008787         -0.005294   \n",
       "roberta-base                  -0.021341         -0.009321         -0.005925   \n",
       "distilroberta-base            -0.012039         -0.005094         -0.002901   \n",
       "albert-base-v2                -0.014013         -0.006288         -0.006921   \n",
       "deberta-base                  -0.030298         -0.013349         -0.007529   \n",
       "gpt2                          -0.020568         -0.008203         -0.006397   \n",
       "\n",
       "                         sst2_total_power  sst2_exp_len_hours  \\\n",
       "model_name                                                      \n",
       "distilbert-base-uncased         -0.040868           -0.150034   \n",
       "bert-base-uncased               -0.074237           -0.283502   \n",
       "roberta-base                    -0.077397           -0.287918   \n",
       "distilroberta-base              -0.041124           -0.159032   \n",
       "albert-base-v2                  -0.064754           -0.195145   \n",
       "deberta-base                    -0.110914           -0.446843   \n",
       "gpt2                            -0.073969           -0.245803   \n",
       "\n",
       "                         mrpc_exp_len_hours  cola_exp_len_hours  \\\n",
       "model_name                                                        \n",
       "distilbert-base-uncased           -0.009880           -0.019829   \n",
       "bert-base-uncased                 -0.018210           -0.036952   \n",
       "roberta-base                      -0.017837           -0.036028   \n",
       "distilroberta-base                -0.010284           -0.020594   \n",
       "albert-base-v2                    -0.015761           -0.023249   \n",
       "deberta-base                      -0.027093           -0.058610   \n",
       "gpt2                              -0.016995           -0.031311   \n",
       "\n",
       "                         mnli-mm_total_power  mnli-mm_kg_carbon  \\\n",
       "model_name                                                        \n",
       "distilbert-base-uncased            -1.059574          -0.265671   \n",
       "bert-base-uncased                  -1.959109          -0.491214   \n",
       "roberta-base                       -1.985482          -0.497827   \n",
       "distilroberta-base                 -0.718782          -0.180223   \n",
       "albert-base-v2                     -2.292798          -0.574881   \n",
       "deberta-base                       -3.716869          -0.931943   \n",
       "gpt2                               -1.997422          -0.500820   \n",
       "\n",
       "                         qnli_total_power  \n",
       "model_name                                 \n",
       "distilbert-base-uncased         -0.249105  \n",
       "bert-base-uncased               -0.504366  \n",
       "roberta-base                    -0.522354  \n",
       "distilroberta-base              -0.243730  \n",
       "albert-base-v2                  -0.529408  \n",
       "deberta-base                    -0.950864  \n",
       "gpt2                            -0.628704  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../tables/case_study_4/glue_hpc.csv\").set_index(\"model_name\").drop(\"t5-base\")\n",
    "ethics = pd.read_csv(\"../tables/case_study_4/social_bias_data.csv\", index_col=\"model_name\").drop(\"t5-base\")\n",
    "tracker = pd.read_csv(\"../tables/case_study_4/experiment_tracker_table.csv\", index_col=\"model_name\")\n",
    "\n",
    "agg_data = data.join(ethics, on=data.index).join(-tracker, on=data.index).astype(float)\n",
    "agg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and winner selection without group weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251.00: distilroberta-base</td>\n",
       "      <td>14.32: roberta-base</td>\n",
       "      <td>nan: distilbert-base-uncased</td>\n",
       "      <td>6.00: distilroberta-base</td>\n",
       "      <td>23.00: distilroberta-base</td>\n",
       "      <td>-0.00: distilroberta-base</td>\n",
       "      <td>35.24: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247.00: distilbert-base-uncased</td>\n",
       "      <td>14.11: distilroberta-base</td>\n",
       "      <td>nan: bert-base-uncased</td>\n",
       "      <td>4.00: distilbert-base-uncased</td>\n",
       "      <td>18.00: distilbert-base-uncased</td>\n",
       "      <td>-31.00: distilbert-base-uncased</td>\n",
       "      <td>32.59: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167.00: bert-base-uncased</td>\n",
       "      <td>13.91: deberta-base</td>\n",
       "      <td>nan: roberta-base</td>\n",
       "      <td>2.00: bert-base-uncased</td>\n",
       "      <td>8.50: deberta-base</td>\n",
       "      <td>-42.00: albert-base-v2</td>\n",
       "      <td>17.02: deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158.50: albert-base-v2</td>\n",
       "      <td>13.87: albert-base-v2</td>\n",
       "      <td>nan: distilroberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>2.00: albert-base-v2</td>\n",
       "      <td>-43.00: deberta-base</td>\n",
       "      <td>16.90: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>144.00: roberta-base</td>\n",
       "      <td>13.86: distilbert-base-uncased</td>\n",
       "      <td>nan: albert-base-v2</td>\n",
       "      <td>-2.00: albert-base-v2</td>\n",
       "      <td>1.00: bert-base-uncased</td>\n",
       "      <td>-44.00: bert-base-uncased</td>\n",
       "      <td>15.37: roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107.00: gpt2</td>\n",
       "      <td>13.74: bert-base-uncased</td>\n",
       "      <td>nan: deberta-base</td>\n",
       "      <td>-4.00: gpt2</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-45.00: roberta-base</td>\n",
       "      <td>15.31: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.50: deberta-base</td>\n",
       "      <td>13.18: gpt2</td>\n",
       "      <td>nan: gpt2</td>\n",
       "      <td>-6.00: deberta-base</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-49.00: gpt2</td>\n",
       "      <td>12.34: gpt2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Borda  \\\n",
       "Ranking position                                    \n",
       "1                      251.00: distilroberta-base   \n",
       "2                 247.00: distilbert-base-uncased   \n",
       "3                       167.00: bert-base-uncased   \n",
       "4                          158.50: albert-base-v2   \n",
       "5                            144.00: roberta-base   \n",
       "6                                    107.00: gpt2   \n",
       "7                             72.50: deberta-base   \n",
       "\n",
       "                                              AM  \\\n",
       "Ranking position                                   \n",
       "1                            14.32: roberta-base   \n",
       "2                      14.11: distilroberta-base   \n",
       "3                            13.91: deberta-base   \n",
       "4                          13.87: albert-base-v2   \n",
       "5                 13.86: distilbert-base-uncased   \n",
       "6                       13.74: bert-base-uncased   \n",
       "7                                    13.18: gpt2   \n",
       "\n",
       "                                            GM                       Copeland  \\\n",
       "Ranking position                                                                \n",
       "1                 nan: distilbert-base-uncased       6.00: distilroberta-base   \n",
       "2                       nan: bert-base-uncased  4.00: distilbert-base-uncased   \n",
       "3                            nan: roberta-base        2.00: bert-base-uncased   \n",
       "4                      nan: distilroberta-base             0.00: roberta-base   \n",
       "5                          nan: albert-base-v2          -2.00: albert-base-v2   \n",
       "6                            nan: deberta-base                    -4.00: gpt2   \n",
       "7                                    nan: gpt2            -6.00: deberta-base   \n",
       "\n",
       "                                       Plurality  \\\n",
       "Ranking position                                   \n",
       "1                      23.00: distilroberta-base   \n",
       "2                 18.00: distilbert-base-uncased   \n",
       "3                             8.50: deberta-base   \n",
       "4                           2.00: albert-base-v2   \n",
       "5                        1.00: bert-base-uncased   \n",
       "6                             0.00: roberta-base   \n",
       "7                                     0.00: gpt2   \n",
       "\n",
       "                                          Minimax  \\\n",
       "Ranking position                                    \n",
       "1                       -0.00: distilroberta-base   \n",
       "2                 -31.00: distilbert-base-uncased   \n",
       "3                          -42.00: albert-base-v2   \n",
       "4                            -43.00: deberta-base   \n",
       "5                       -44.00: bert-base-uncased   \n",
       "6                            -45.00: roberta-base   \n",
       "7                                    -49.00: gpt2   \n",
       "\n",
       "                                         Dowdall  \n",
       "Ranking position                                  \n",
       "1                      35.24: distilroberta-base  \n",
       "2                 32.59: distilbert-base-uncased  \n",
       "3                            17.02: deberta-base  \n",
       "4                          16.90: albert-base-v2  \n",
       "5                            15.37: roberta-base  \n",
       "6                       15.31: bert-base-uncased  \n",
       "7                                    12.34: gpt2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = {col: 0.5 for col in agg_data.columns if col.split(\".\")[0] in [\"stsb\", \"mrpc\", \"qqp\"]}\n",
    "naive_lb = Leaderboard(agg_data, weights=weights)\n",
    "naive_lb.rank_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borda</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AM</td>\n",
       "      <td>[roberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condorcet</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copeland</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plurality</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Threshold</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Minimax</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dowdall</td>\n",
       "      <td>[distilroberta-base]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method               winners\n",
       "0      Borda  [distilroberta-base]\n",
       "1         AM        [roberta-base]\n",
       "2         GM                    []\n",
       "3  Condorcet  [distilroberta-base]\n",
       "4   Copeland  [distilroberta-base]\n",
       "5    Baldwin  [distilroberta-base]\n",
       "6  Plurality  [distilroberta-base]\n",
       "7  Threshold  [distilroberta-base]\n",
       "8    Minimax  [distilroberta-base]\n",
       "9    Dowdall  [distilroberta-base]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_lb.elect_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted ranking: performance, efficiency and social bias have equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "wnli.eval_accuracy                0.076923\n",
       "cola.eval_matthews_correlation    0.076923\n",
       "stsb.eval_pearson                 0.038462\n",
       "stsb.eval_spearmanr               0.038462\n",
       "rte.eval_accuracy                 0.076923\n",
       "mrpc.eval_accuracy                0.038462\n",
       "mrpc.eval_f1                      0.038462\n",
       "sst2.eval_accuracy                0.076923\n",
       "qnli.eval_accuracy                0.076923\n",
       "qqp.eval_accuracy                 0.038462\n",
       "qqp.eval_f1                       0.038462\n",
       "mnli.eval_accuracy                0.076923\n",
       "mnli-mm.eval_accuracy             0.076923\n",
       "anti_crows_score                  0.200000\n",
       "stereoset_intra_icat              0.200000\n",
       "stereoset_inter_icat              0.200000\n",
       "winogender_acc_difference         0.200000\n",
       "winobias_acc_difference           0.200000\n",
       "rte_gpu_hours                     0.025000\n",
       "stsb_kg_carbon                    0.025000\n",
       "wnli_total_power                  0.025000\n",
       "stsb_total_power                  0.025000\n",
       "mnli_total_power                  0.025000\n",
       "qnli_kg_carbon                    0.025000\n",
       "mnli-mm_exp_len_hours             0.025000\n",
       "qnli_exp_len_hours                0.025000\n",
       "qqp_exp_len_hours                 0.025000\n",
       "rte_total_power                   0.025000\n",
       "rte_kg_carbon                     0.025000\n",
       "sst2_kg_carbon                    0.025000\n",
       "qqp_kg_carbon                     0.025000\n",
       "rte_exp_len_hours                 0.025000\n",
       "qnli_gpu_hours                    0.025000\n",
       "qqp_gpu_hours                     0.025000\n",
       "mnli_exp_len_hours                0.025000\n",
       "mrpc_gpu_hours                    0.025000\n",
       "wnli_gpu_hours                    0.025000\n",
       "wnli_kg_carbon                    0.025000\n",
       "stsb_exp_len_hours                0.025000\n",
       "mrpc_kg_carbon                    0.025000\n",
       "mnli-mm_gpu_hours                 0.025000\n",
       "mnli_kg_carbon                    0.025000\n",
       "wnli_exp_len_hours                0.025000\n",
       "stsb_gpu_hours                    0.025000\n",
       "sst2_gpu_hours                    0.025000\n",
       "mnli_gpu_hours                    0.025000\n",
       "qqp_total_power                   0.025000\n",
       "cola_kg_carbon                    0.025000\n",
       "cola_gpu_hours                    0.025000\n",
       "cola_total_power                  0.025000\n",
       "mrpc_total_power                  0.025000\n",
       "sst2_total_power                  0.025000\n",
       "sst2_exp_len_hours                0.025000\n",
       "mrpc_exp_len_hours                0.025000\n",
       "cola_exp_len_hours                0.025000\n",
       "mnli-mm_total_power               0.025000\n",
       "mnli-mm_kg_carbon                 0.025000\n",
       "qnli_total_power                  0.025000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_groups = {\n",
    "    \"metrics\": data.columns.tolist(),\n",
    "    \"efficiency\": tracker.columns.tolist(),\n",
    "    \"ethics\": ethics.columns.tolist()\n",
    "}\n",
    "\n",
    "group_weights = naive_lb.weights.copy()\n",
    "\n",
    "for column in agg_data.columns:\n",
    "    for group, tasks in task_groups.items():\n",
    "        if column in tasks:\n",
    "            group_weights.loc[column] /= len(tasks)\n",
    "\n",
    "print(\"Group weights\")\n",
    "group_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.25: distilbert-base-uncased</td>\n",
       "      <td>22.79: roberta-base</td>\n",
       "      <td>nan: distilbert-base-uncased</td>\n",
       "      <td>6.00: distilbert-base-uncased</td>\n",
       "      <td>0.78: deberta-base</td>\n",
       "      <td>-0.00: distilbert-base-uncased</td>\n",
       "      <td>1.34: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.67: albert-base-v2</td>\n",
       "      <td>22.63: deberta-base</td>\n",
       "      <td>nan: bert-base-uncased</td>\n",
       "      <td>4.00: albert-base-v2</td>\n",
       "      <td>0.63: distilbert-base-uncased</td>\n",
       "      <td>-1.45: albert-base-v2</td>\n",
       "      <td>1.30: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.08: distilroberta-base</td>\n",
       "      <td>22.31: albert-base-v2</td>\n",
       "      <td>nan: roberta-base</td>\n",
       "      <td>2.00: distilroberta-base</td>\n",
       "      <td>0.58: distilroberta-base</td>\n",
       "      <td>-1.46: distilroberta-base</td>\n",
       "      <td>1.24: deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.46: bert-base-uncased</td>\n",
       "      <td>21.97: distilroberta-base</td>\n",
       "      <td>nan: distilroberta-base</td>\n",
       "      <td>0.00: bert-base-uncased</td>\n",
       "      <td>0.28: albert-base-v2</td>\n",
       "      <td>-1.68: bert-base-uncased</td>\n",
       "      <td>1.18: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.02: deberta-base</td>\n",
       "      <td>21.91: bert-base-uncased</td>\n",
       "      <td>nan: albert-base-v2</td>\n",
       "      <td>-4.00: roberta-base</td>\n",
       "      <td>0.20: bert-base-uncased</td>\n",
       "      <td>-1.83: deberta-base</td>\n",
       "      <td>0.87: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.84: roberta-base</td>\n",
       "      <td>21.73: distilbert-base-uncased</td>\n",
       "      <td>nan: deberta-base</td>\n",
       "      <td>-4.00: deberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-2.00: roberta-base</td>\n",
       "      <td>0.82: roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.72: gpt2</td>\n",
       "      <td>21.02: gpt2</td>\n",
       "      <td>nan: gpt2</td>\n",
       "      <td>-4.00: gpt2</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-2.06: gpt2</td>\n",
       "      <td>0.76: gpt2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Borda  \\\n",
       "Ranking position                                   \n",
       "1                 10.25: distilbert-base-uncased   \n",
       "2                           9.67: albert-base-v2   \n",
       "3                       9.08: distilroberta-base   \n",
       "4                        8.46: bert-base-uncased   \n",
       "5                             7.02: deberta-base   \n",
       "6                             6.84: roberta-base   \n",
       "7                                     5.72: gpt2   \n",
       "\n",
       "                                              AM  \\\n",
       "Ranking position                                   \n",
       "1                            22.79: roberta-base   \n",
       "2                            22.63: deberta-base   \n",
       "3                          22.31: albert-base-v2   \n",
       "4                      21.97: distilroberta-base   \n",
       "5                       21.91: bert-base-uncased   \n",
       "6                 21.73: distilbert-base-uncased   \n",
       "7                                    21.02: gpt2   \n",
       "\n",
       "                                            GM                       Copeland  \\\n",
       "Ranking position                                                                \n",
       "1                 nan: distilbert-base-uncased  6.00: distilbert-base-uncased   \n",
       "2                       nan: bert-base-uncased           4.00: albert-base-v2   \n",
       "3                            nan: roberta-base       2.00: distilroberta-base   \n",
       "4                      nan: distilroberta-base        0.00: bert-base-uncased   \n",
       "5                          nan: albert-base-v2            -4.00: roberta-base   \n",
       "6                            nan: deberta-base            -4.00: deberta-base   \n",
       "7                                    nan: gpt2                    -4.00: gpt2   \n",
       "\n",
       "                                      Plurality  \\\n",
       "Ranking position                                  \n",
       "1                            0.78: deberta-base   \n",
       "2                 0.63: distilbert-base-uncased   \n",
       "3                      0.58: distilroberta-base   \n",
       "4                          0.28: albert-base-v2   \n",
       "5                       0.20: bert-base-uncased   \n",
       "6                            0.00: roberta-base   \n",
       "7                                    0.00: gpt2   \n",
       "\n",
       "                                         Minimax  \\\n",
       "Ranking position                                   \n",
       "1                 -0.00: distilbert-base-uncased   \n",
       "2                          -1.45: albert-base-v2   \n",
       "3                      -1.46: distilroberta-base   \n",
       "4                       -1.68: bert-base-uncased   \n",
       "5                            -1.83: deberta-base   \n",
       "6                            -2.00: roberta-base   \n",
       "7                                    -2.06: gpt2   \n",
       "\n",
       "                                        Dowdall  \n",
       "Ranking position                                 \n",
       "1                 1.34: distilbert-base-uncased  \n",
       "2                      1.30: distilroberta-base  \n",
       "3                            1.24: deberta-base  \n",
       "4                          1.18: albert-base-v2  \n",
       "5                       0.87: bert-base-uncased  \n",
       "6                            0.82: roberta-base  \n",
       "7                                    0.76: gpt2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_lb = Leaderboard(agg_data, weights=group_weights.to_dict())\n",
    "weighted_lb.rank_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borda</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AM</td>\n",
       "      <td>[roberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GM</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condorcet</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Copeland</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baldwin</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plurality</td>\n",
       "      <td>[deberta-base]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Threshold</td>\n",
       "      <td>[albert-base-v2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Minimax</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dowdall</td>\n",
       "      <td>[distilbert-base-uncased]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method                    winners\n",
       "0      Borda  [distilbert-base-uncased]\n",
       "1         AM             [roberta-base]\n",
       "2         GM                         []\n",
       "3  Condorcet  [distilbert-base-uncased]\n",
       "4   Copeland  [distilbert-base-uncased]\n",
       "5    Baldwin  [distilbert-base-uncased]\n",
       "6  Plurality             [deberta-base]\n",
       "7  Threshold           [albert-base-v2]\n",
       "8    Minimax  [distilbert-base-uncased]\n",
       "9    Dowdall  [distilbert-base-uncased]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_lb.elect_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking with respect to groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking according to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.50: deberta-base</td>\n",
       "      <td>82.73: deberta-base</td>\n",
       "      <td>81.56: deberta-base</td>\n",
       "      <td>6.00: deberta-base</td>\n",
       "      <td>7.50: deberta-base</td>\n",
       "      <td>-0.00: deberta-base</td>\n",
       "      <td>9.33: deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.00: roberta-base</td>\n",
       "      <td>82.52: roberta-base</td>\n",
       "      <td>81.34: roberta-base</td>\n",
       "      <td>4.00: roberta-base</td>\n",
       "      <td>1.00: albert-base-v2</td>\n",
       "      <td>-7.50: roberta-base</td>\n",
       "      <td>5.67: roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.50: albert-base-v2</td>\n",
       "      <td>80.94: albert-base-v2</td>\n",
       "      <td>79.65: albert-base-v2</td>\n",
       "      <td>2.00: bert-base-uncased</td>\n",
       "      <td>0.00: distilbert-base-uncased</td>\n",
       "      <td>-9.00: albert-base-v2</td>\n",
       "      <td>3.57: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.00: bert-base-uncased</td>\n",
       "      <td>79.20: bert-base-uncased</td>\n",
       "      <td>77.19: bert-base-uncased</td>\n",
       "      <td>0.00: albert-base-v2</td>\n",
       "      <td>0.00: bert-base-uncased</td>\n",
       "      <td>-10.00: distilbert-base-uncased</td>\n",
       "      <td>2.89: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.00: distilroberta-base</td>\n",
       "      <td>78.56: distilroberta-base</td>\n",
       "      <td>77.05: distilroberta-base</td>\n",
       "      <td>-2.00: distilroberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-10.00: bert-base-uncased</td>\n",
       "      <td>1.95: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.00: distilbert-base-uncased</td>\n",
       "      <td>77.89: distilbert-base-uncased</td>\n",
       "      <td>76.46: distilbert-base-uncased</td>\n",
       "      <td>-4.00: distilbert-base-uncased</td>\n",
       "      <td>0.00: distilroberta-base</td>\n",
       "      <td>-10.00: distilroberta-base</td>\n",
       "      <td>1.80: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.00: gpt2</td>\n",
       "      <td>75.95: gpt2</td>\n",
       "      <td>73.56: gpt2</td>\n",
       "      <td>-6.00: gpt2</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-10.00: gpt2</td>\n",
       "      <td>1.66: gpt2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Borda  \\\n",
       "Ranking position                                   \n",
       "1                            56.50: deberta-base   \n",
       "2                            49.00: roberta-base   \n",
       "3                          32.50: albert-base-v2   \n",
       "4                       32.00: bert-base-uncased   \n",
       "5                      17.00: distilroberta-base   \n",
       "6                 11.00: distilbert-base-uncased   \n",
       "7                                     8.00: gpt2   \n",
       "\n",
       "                                              AM  \\\n",
       "Ranking position                                   \n",
       "1                            82.73: deberta-base   \n",
       "2                            82.52: roberta-base   \n",
       "3                          80.94: albert-base-v2   \n",
       "4                       79.20: bert-base-uncased   \n",
       "5                      78.56: distilroberta-base   \n",
       "6                 77.89: distilbert-base-uncased   \n",
       "7                                    75.95: gpt2   \n",
       "\n",
       "                                              GM  \\\n",
       "Ranking position                                   \n",
       "1                            81.56: deberta-base   \n",
       "2                            81.34: roberta-base   \n",
       "3                          79.65: albert-base-v2   \n",
       "4                       77.19: bert-base-uncased   \n",
       "5                      77.05: distilroberta-base   \n",
       "6                 76.46: distilbert-base-uncased   \n",
       "7                                    73.56: gpt2   \n",
       "\n",
       "                                        Copeland  \\\n",
       "Ranking position                                   \n",
       "1                             6.00: deberta-base   \n",
       "2                             4.00: roberta-base   \n",
       "3                        2.00: bert-base-uncased   \n",
       "4                           0.00: albert-base-v2   \n",
       "5                      -2.00: distilroberta-base   \n",
       "6                 -4.00: distilbert-base-uncased   \n",
       "7                                    -6.00: gpt2   \n",
       "\n",
       "                                      Plurality  \\\n",
       "Ranking position                                  \n",
       "1                            7.50: deberta-base   \n",
       "2                          1.00: albert-base-v2   \n",
       "3                 0.00: distilbert-base-uncased   \n",
       "4                       0.00: bert-base-uncased   \n",
       "5                            0.00: roberta-base   \n",
       "6                      0.00: distilroberta-base   \n",
       "7                                    0.00: gpt2   \n",
       "\n",
       "                                          Minimax  \\\n",
       "Ranking position                                    \n",
       "1                             -0.00: deberta-base   \n",
       "2                             -7.50: roberta-base   \n",
       "3                           -9.00: albert-base-v2   \n",
       "4                 -10.00: distilbert-base-uncased   \n",
       "5                       -10.00: bert-base-uncased   \n",
       "6                      -10.00: distilroberta-base   \n",
       "7                                    -10.00: gpt2   \n",
       "\n",
       "                                        Dowdall  \n",
       "Ranking position                                 \n",
       "1                            9.33: deberta-base  \n",
       "2                            5.67: roberta-base  \n",
       "3                          3.57: albert-base-v2  \n",
       "4                       2.89: bert-base-uncased  \n",
       "5                      1.95: distilroberta-base  \n",
       "6                 1.80: distilbert-base-uncased  \n",
       "7                                    1.66: gpt2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Leaderboard(agg_data[task_groups[\"metrics\"]], \n",
    "            weights=naive_lb.weights[task_groups[\"metrics\"]].to_dict()).rank_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking according to efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223.00: distilroberta-base</td>\n",
       "      <td>-0.34: distilroberta-base</td>\n",
       "      <td>nan: distilbert-base-uncased</td>\n",
       "      <td>6.00: distilroberta-base</td>\n",
       "      <td>23.00: distilroberta-base</td>\n",
       "      <td>-0.00: distilroberta-base</td>\n",
       "      <td>31.50: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216.00: distilbert-base-uncased</td>\n",
       "      <td>-0.51: distilbert-base-uncased</td>\n",
       "      <td>nan: bert-base-uncased</td>\n",
       "      <td>4.00: distilbert-base-uncased</td>\n",
       "      <td>17.00: distilbert-base-uncased</td>\n",
       "      <td>-23.00: distilbert-base-uncased</td>\n",
       "      <td>28.33: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.00: bert-base-uncased</td>\n",
       "      <td>-0.96: gpt2</td>\n",
       "      <td>nan: roberta-base</td>\n",
       "      <td>2.00: bert-base-uncased</td>\n",
       "      <td>0.00: bert-base-uncased</td>\n",
       "      <td>-40.00: bert-base-uncased</td>\n",
       "      <td>10.50: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.00: albert-base-v2</td>\n",
       "      <td>-1.00: bert-base-uncased</td>\n",
       "      <td>nan: distilroberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-40.00: roberta-base</td>\n",
       "      <td>10.09: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.00: roberta-base</td>\n",
       "      <td>-1.03: roberta-base</td>\n",
       "      <td>nan: albert-base-v2</td>\n",
       "      <td>-2.00: albert-base-v2</td>\n",
       "      <td>0.00: albert-base-v2</td>\n",
       "      <td>-40.00: albert-base-v2</td>\n",
       "      <td>8.88: roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84.00: gpt2</td>\n",
       "      <td>-1.26: albert-base-v2</td>\n",
       "      <td>nan: deberta-base</td>\n",
       "      <td>-4.00: gpt2</td>\n",
       "      <td>0.00: deberta-base</td>\n",
       "      <td>-40.00: deberta-base</td>\n",
       "      <td>8.62: gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.00: deberta-base</td>\n",
       "      <td>-1.64: deberta-base</td>\n",
       "      <td>nan: gpt2</td>\n",
       "      <td>-6.00: deberta-base</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-40.00: gpt2</td>\n",
       "      <td>5.80: deberta-base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Borda  \\\n",
       "Ranking position                                    \n",
       "1                      223.00: distilroberta-base   \n",
       "2                 216.00: distilbert-base-uncased   \n",
       "3                       120.00: bert-base-uncased   \n",
       "4                          103.00: albert-base-v2   \n",
       "5                             91.00: roberta-base   \n",
       "6                                     84.00: gpt2   \n",
       "7                              3.00: deberta-base   \n",
       "\n",
       "                                              AM  \\\n",
       "Ranking position                                   \n",
       "1                      -0.34: distilroberta-base   \n",
       "2                 -0.51: distilbert-base-uncased   \n",
       "3                                    -0.96: gpt2   \n",
       "4                       -1.00: bert-base-uncased   \n",
       "5                            -1.03: roberta-base   \n",
       "6                          -1.26: albert-base-v2   \n",
       "7                            -1.64: deberta-base   \n",
       "\n",
       "                                            GM                       Copeland  \\\n",
       "Ranking position                                                                \n",
       "1                 nan: distilbert-base-uncased       6.00: distilroberta-base   \n",
       "2                       nan: bert-base-uncased  4.00: distilbert-base-uncased   \n",
       "3                            nan: roberta-base        2.00: bert-base-uncased   \n",
       "4                      nan: distilroberta-base             0.00: roberta-base   \n",
       "5                          nan: albert-base-v2          -2.00: albert-base-v2   \n",
       "6                            nan: deberta-base                    -4.00: gpt2   \n",
       "7                                    nan: gpt2            -6.00: deberta-base   \n",
       "\n",
       "                                       Plurality  \\\n",
       "Ranking position                                   \n",
       "1                      23.00: distilroberta-base   \n",
       "2                 17.00: distilbert-base-uncased   \n",
       "3                        0.00: bert-base-uncased   \n",
       "4                             0.00: roberta-base   \n",
       "5                           0.00: albert-base-v2   \n",
       "6                             0.00: deberta-base   \n",
       "7                                     0.00: gpt2   \n",
       "\n",
       "                                          Minimax  \\\n",
       "Ranking position                                    \n",
       "1                       -0.00: distilroberta-base   \n",
       "2                 -23.00: distilbert-base-uncased   \n",
       "3                       -40.00: bert-base-uncased   \n",
       "4                            -40.00: roberta-base   \n",
       "5                          -40.00: albert-base-v2   \n",
       "6                            -40.00: deberta-base   \n",
       "7                                    -40.00: gpt2   \n",
       "\n",
       "                                         Dowdall  \n",
       "Ranking position                                  \n",
       "1                      31.50: distilroberta-base  \n",
       "2                 28.33: distilbert-base-uncased  \n",
       "3                       10.50: bert-base-uncased  \n",
       "4                          10.09: albert-base-v2  \n",
       "5                             8.88: roberta-base  \n",
       "6                                     8.62: gpt2  \n",
       "7                             5.80: deberta-base  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Leaderboard(agg_data[task_groups[\"efficiency\"]], \n",
    "            weights=naive_lb.weights[task_groups[\"efficiency\"]].to_dict()).rank_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking according to social bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.00: albert-base-v2</td>\n",
       "      <td>0.78: albert-base-v2</td>\n",
       "      <td>0.75: albert-base-v2</td>\n",
       "      <td>6.00: albert-base-v2</td>\n",
       "      <td>1.00: distilbert-base-uncased</td>\n",
       "      <td>-0.00: albert-base-v2</td>\n",
       "      <td>3.25: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.00: distilbert-base-uncased</td>\n",
       "      <td>0.77: distilbert-base-uncased</td>\n",
       "      <td>0.73: distilbert-base-uncased</td>\n",
       "      <td>4.00: distilbert-base-uncased</td>\n",
       "      <td>1.00: bert-base-uncased</td>\n",
       "      <td>-3.00: distilbert-base-uncased</td>\n",
       "      <td>2.45: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.00: bert-base-uncased</td>\n",
       "      <td>0.75: bert-base-uncased</td>\n",
       "      <td>0.72: bert-base-uncased</td>\n",
       "      <td>0.00: bert-base-uncased</td>\n",
       "      <td>1.00: albert-base-v2</td>\n",
       "      <td>-3.00: gpt2</td>\n",
       "      <td>2.06: gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.00: gpt2</td>\n",
       "      <td>0.74: gpt2</td>\n",
       "      <td>0.71: gpt2</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>1.00: deberta-base</td>\n",
       "      <td>-4.00: bert-base-uncased</td>\n",
       "      <td>1.92: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.00: deberta-base</td>\n",
       "      <td>0.73: distilroberta-base</td>\n",
       "      <td>0.69: distilroberta-base</td>\n",
       "      <td>-2.00: distilroberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-4.00: distilroberta-base</td>\n",
       "      <td>1.89: deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.00: distilroberta-base</td>\n",
       "      <td>0.68: roberta-base</td>\n",
       "      <td>0.62: roberta-base</td>\n",
       "      <td>-2.00: deberta-base</td>\n",
       "      <td>0.00: distilroberta-base</td>\n",
       "      <td>-4.00: deberta-base</td>\n",
       "      <td>1.79: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.00: roberta-base</td>\n",
       "      <td>0.66: deberta-base</td>\n",
       "      <td>0.61: deberta-base</td>\n",
       "      <td>-6.00: roberta-base</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-5.00: roberta-base</td>\n",
       "      <td>0.82: roberta-base</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Borda  \\\n",
       "Ranking position                                   \n",
       "1                          23.00: albert-base-v2   \n",
       "2                 20.00: distilbert-base-uncased   \n",
       "3                       15.00: bert-base-uncased   \n",
       "4                                    15.00: gpt2   \n",
       "5                            13.00: deberta-base   \n",
       "6                      11.00: distilroberta-base   \n",
       "7                             4.00: roberta-base   \n",
       "\n",
       "                                             AM  \\\n",
       "Ranking position                                  \n",
       "1                          0.78: albert-base-v2   \n",
       "2                 0.77: distilbert-base-uncased   \n",
       "3                       0.75: bert-base-uncased   \n",
       "4                                    0.74: gpt2   \n",
       "5                      0.73: distilroberta-base   \n",
       "6                            0.68: roberta-base   \n",
       "7                            0.66: deberta-base   \n",
       "\n",
       "                                             GM  \\\n",
       "Ranking position                                  \n",
       "1                          0.75: albert-base-v2   \n",
       "2                 0.73: distilbert-base-uncased   \n",
       "3                       0.72: bert-base-uncased   \n",
       "4                                    0.71: gpt2   \n",
       "5                      0.69: distilroberta-base   \n",
       "6                            0.62: roberta-base   \n",
       "7                            0.61: deberta-base   \n",
       "\n",
       "                                       Copeland  \\\n",
       "Ranking position                                  \n",
       "1                          6.00: albert-base-v2   \n",
       "2                 4.00: distilbert-base-uncased   \n",
       "3                       0.00: bert-base-uncased   \n",
       "4                                    0.00: gpt2   \n",
       "5                     -2.00: distilroberta-base   \n",
       "6                           -2.00: deberta-base   \n",
       "7                           -6.00: roberta-base   \n",
       "\n",
       "                                      Plurality  \\\n",
       "Ranking position                                  \n",
       "1                 1.00: distilbert-base-uncased   \n",
       "2                       1.00: bert-base-uncased   \n",
       "3                          1.00: albert-base-v2   \n",
       "4                            1.00: deberta-base   \n",
       "5                            0.00: roberta-base   \n",
       "6                      0.00: distilroberta-base   \n",
       "7                                    0.00: gpt2   \n",
       "\n",
       "                                         Minimax  \\\n",
       "Ranking position                                   \n",
       "1                          -0.00: albert-base-v2   \n",
       "2                 -3.00: distilbert-base-uncased   \n",
       "3                                    -3.00: gpt2   \n",
       "4                       -4.00: bert-base-uncased   \n",
       "5                      -4.00: distilroberta-base   \n",
       "6                            -4.00: deberta-base   \n",
       "7                            -5.00: roberta-base   \n",
       "\n",
       "                                        Dowdall  \n",
       "Ranking position                                 \n",
       "1                          3.25: albert-base-v2  \n",
       "2                 2.45: distilbert-base-uncased  \n",
       "3                                    2.06: gpt2  \n",
       "4                       1.92: bert-base-uncased  \n",
       "5                            1.89: deberta-base  \n",
       "6                      1.79: distilroberta-base  \n",
       "7                            0.82: roberta-base  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Leaderboard(agg_data[task_groups[\"ethics\"]], \n",
    "            weights=naive_lb.weights[task_groups[\"ethics\"]].to_dict()).rank_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-step ranking with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borda</th>\n",
       "      <th>AM</th>\n",
       "      <th>GM</th>\n",
       "      <th>Copeland</th>\n",
       "      <th>Plurality</th>\n",
       "      <th>Minimax</th>\n",
       "      <th>Dowdall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ranking position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.30: albert-base-v2</td>\n",
       "      <td>32.90: roberta-base</td>\n",
       "      <td>nan: distilbert-base-uncased</td>\n",
       "      <td>4.00: bert-base-uncased</td>\n",
       "      <td>0.40: deberta-base</td>\n",
       "      <td>-0.40: albert-base-v2</td>\n",
       "      <td>0.51: albert-base-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.40: distilbert-base-uncased</td>\n",
       "      <td>32.80: deberta-base</td>\n",
       "      <td>nan: bert-base-uncased</td>\n",
       "      <td>2.00: distilbert-base-uncased</td>\n",
       "      <td>0.30: distilroberta-base</td>\n",
       "      <td>-0.60: deberta-base</td>\n",
       "      <td>0.50: deberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.30: bert-base-uncased</td>\n",
       "      <td>32.23: albert-base-v2</td>\n",
       "      <td>nan: roberta-base</td>\n",
       "      <td>2.00: albert-base-v2</td>\n",
       "      <td>0.00: distilbert-base-uncased</td>\n",
       "      <td>-0.70: distilbert-base-uncased</td>\n",
       "      <td>0.43: distilroberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00: deberta-base</td>\n",
       "      <td>31.61: bert-base-uncased</td>\n",
       "      <td>nan: distilroberta-base</td>\n",
       "      <td>0.00: distilroberta-base</td>\n",
       "      <td>0.00: bert-base-uncased</td>\n",
       "      <td>-0.70: bert-base-uncased</td>\n",
       "      <td>0.37: distilbert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.90: distilroberta-base</td>\n",
       "      <td>31.54: distilroberta-base</td>\n",
       "      <td>nan: albert-base-v2</td>\n",
       "      <td>-2.00: roberta-base</td>\n",
       "      <td>0.00: roberta-base</td>\n",
       "      <td>-0.70: roberta-base</td>\n",
       "      <td>0.30: roberta-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.60: roberta-base</td>\n",
       "      <td>31.23: distilbert-base-uncased</td>\n",
       "      <td>nan: deberta-base</td>\n",
       "      <td>-2.00: deberta-base</td>\n",
       "      <td>0.00: albert-base-v2</td>\n",
       "      <td>-0.70: distilroberta-base</td>\n",
       "      <td>0.28: bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.20: gpt2</td>\n",
       "      <td>30.32: gpt2</td>\n",
       "      <td>nan: gpt2</td>\n",
       "      <td>-4.00: gpt2</td>\n",
       "      <td>0.00: gpt2</td>\n",
       "      <td>-0.70: gpt2</td>\n",
       "      <td>0.21: gpt2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Borda  \\\n",
       "Ranking position                                  \n",
       "1                          4.30: albert-base-v2   \n",
       "2                 3.40: distilbert-base-uncased   \n",
       "3                       3.30: bert-base-uncased   \n",
       "4                            3.00: deberta-base   \n",
       "5                      2.90: distilroberta-base   \n",
       "6                            2.60: roberta-base   \n",
       "7                                    1.20: gpt2   \n",
       "\n",
       "                                              AM  \\\n",
       "Ranking position                                   \n",
       "1                            32.90: roberta-base   \n",
       "2                            32.80: deberta-base   \n",
       "3                          32.23: albert-base-v2   \n",
       "4                       31.61: bert-base-uncased   \n",
       "5                      31.54: distilroberta-base   \n",
       "6                 31.23: distilbert-base-uncased   \n",
       "7                                    30.32: gpt2   \n",
       "\n",
       "                                            GM                       Copeland  \\\n",
       "Ranking position                                                                \n",
       "1                 nan: distilbert-base-uncased        4.00: bert-base-uncased   \n",
       "2                       nan: bert-base-uncased  2.00: distilbert-base-uncased   \n",
       "3                            nan: roberta-base           2.00: albert-base-v2   \n",
       "4                      nan: distilroberta-base       0.00: distilroberta-base   \n",
       "5                          nan: albert-base-v2            -2.00: roberta-base   \n",
       "6                            nan: deberta-base            -2.00: deberta-base   \n",
       "7                                    nan: gpt2                    -4.00: gpt2   \n",
       "\n",
       "                                      Plurality  \\\n",
       "Ranking position                                  \n",
       "1                            0.40: deberta-base   \n",
       "2                      0.30: distilroberta-base   \n",
       "3                 0.00: distilbert-base-uncased   \n",
       "4                       0.00: bert-base-uncased   \n",
       "5                            0.00: roberta-base   \n",
       "6                          0.00: albert-base-v2   \n",
       "7                                    0.00: gpt2   \n",
       "\n",
       "                                         Minimax  \\\n",
       "Ranking position                                   \n",
       "1                          -0.40: albert-base-v2   \n",
       "2                            -0.60: deberta-base   \n",
       "3                 -0.70: distilbert-base-uncased   \n",
       "4                       -0.70: bert-base-uncased   \n",
       "5                            -0.70: roberta-base   \n",
       "6                      -0.70: distilroberta-base   \n",
       "7                                    -0.70: gpt2   \n",
       "\n",
       "                                        Dowdall  \n",
       "Ranking position                                 \n",
       "1                          0.51: albert-base-v2  \n",
       "2                            0.50: deberta-base  \n",
       "3                      0.43: distilroberta-base  \n",
       "4                 0.37: distilbert-base-uncased  \n",
       "5                            0.30: roberta-base  \n",
       "6                       0.28: bert-base-uncased  \n",
       "7                                    0.21: gpt2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_weights = {\n",
    "    \"metrics\": 0.4,\n",
    "    \"efficiency\": 0.3,\n",
    "    \"ethics\": 0.3\n",
    "}\n",
    "\n",
    "naive_lb.rank_all(task_groups=task_groups, group_weights=group_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
